{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c16a98f",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2871cde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraires\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4606eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "\n",
    "df = pd.read_csv('C:/Users/umar/Documents/Machine Learning/Recommender System/Data Analysis/data.csv', index_col=0)\n",
    "df.shape\n",
    "\n",
    "df_title = pd.read_csv('C:/Users/umar/Documents/Machine Learning/Recommender System/Data/movie_titles.csv', header = None, names = ['Movie_Id', 'Year', 'Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd2bee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRIAL, adding all rows from the dataset not just 10k rows\n",
    "\n",
    "def read_text(path):\n",
    "    data = {'Cust_Id' : [], 'Movie_Id' : [], 'Rating' : [], 'Date' : []}  #Creating dictionary to store each attribute \n",
    "    f = open(path, \"r\")\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        count += 1   # As right now we will be using only 10k data\n",
    "        #if count > rows:\n",
    "        #    break\n",
    "            \n",
    "        if ':' in line:\n",
    "            movidId = line[:-2] # remove the last character ':'\n",
    "            movieId = int(movidId)\n",
    "        else:\n",
    "            customerID, rating, date = line.split(',')\n",
    "            data['Cust_Id'].append(customerID)\n",
    "            data['Movie_Id'].append(movieId)\n",
    "            data['Rating'].append(rating)\n",
    "            data['Date'].append(date.rstrip(\"\\n\"))  # rstrip(\"\\n\") removes the trainling character \"\\n\"\n",
    "    f.close()\n",
    "            \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "#df1 = read_text('C:/Users/umar/Documents/Machine Learning/Recommender System/Data/combined_data_1.txt')\n",
    "#df2 = read_text('C:/Users/umar/Documents/Machine Learning/Recommender System/Data/combined_data_2.txt')\n",
    "#df3 = read_text('C:/Users/umar/Documents/Machine Learning/Recommender System/Data/combined_data_3.txt')\n",
    "#df4 = read_text('C:/Users/umar/Documents/Machine Learning/Recommender System/Data/combined_data_4.txt')\n",
    "\n",
    "# converting ratings into float\n",
    "# (example: '3'->3.0)\n",
    "\n",
    "#df1['Rating'] = df1['Rating'].astype(float)\n",
    "#df2['Rating'] = df2['Rating'].astype(float)\n",
    "#df3['Rating'] = df3['Rating'].astype(float)\n",
    "#df4['Rating'] = df4['Rating'].astype(float)\n",
    "\n",
    "#df = df1.copy()\n",
    "#df = df.append(df2)\n",
    "#df = df.append(df3)\n",
    "#df = df.append(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed23600e",
   "metadata": {},
   "source": [
    "Conclusion : Laptop Crashed\n",
    "\n",
    "At a later stage, Finally I will train my model using the whole dataset and not just 10k data, for a better result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d6d134",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6f6962",
   "metadata": {},
   "source": [
    "As of now : No Missing (NA) values, No Categorical Features.\n",
    "\n",
    "And as I am using just 10k data, I do not require Data Slicing. At a later stage when I will use a larger dataset, I will be performing Data Cleaning and Data Slicing for better performance.\n",
    "\n",
    "Data to be removed with larger dataset : (1) Remove movies with too few reviews (they are relatively not popular) (2) Remove customers who give too few reviews (they are relatively less active), this will improve the quality of the data. I will be focusing more on active customers and popular movies. This should improve the statistical significance too.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
